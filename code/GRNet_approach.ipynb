{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f981a1ef",
   "metadata": {},
   "source": [
    "# Goal Recognition as a Deep Learning Task: the GRNet Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525789f",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cfc4384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 09:36:03.048134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-05 09:36:03.174013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-11-05 09:36:03.174035: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-11-05 09:36:03.207844: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-05 09:36:03.849366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-11-05 09:36:03.849452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-11-05 09:36:03.849461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-11-05 09:36:03.849366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-11-05 09:36:03.849452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-11-05 09:36:03.849461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from os.path import join\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import tensorflow.keras.backend as K\n",
    "from typing import Union\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.initializers import Constant\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3a8c",
   "metadata": {},
   "source": [
    "## Custom Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771871d",
   "metadata": {},
   "source": [
    "### Network classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48341cba",
   "metadata": {},
   "source": [
    "Code from \n",
    "*Yang, Z.; Yang, D.; Dyer, C.; He, X.; Smola, A. J.; and Hovy, E. H.* 2016. **Hierarchical Attention Networks for Document Classification**\n",
    "https://github.com/philipperemy/keras-attention-mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50de033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeights(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        # self.init = initializers.get(Constant(value=1))\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(AttentionWeights, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        return a\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        config={'step_dim':self.step_dim}\n",
    "        base_config = super(AttentionWeights, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ContextVector(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ContextVector, self).__init__(**kwargs)\n",
    "        self.features_dim = 0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        self.features_dim = input_shape[0][-1]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        assert len(x) == 2\n",
    "        h = x[0]\n",
    "        a = x[1]\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = h * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0], self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(ContextVector, self).get_config()\n",
    "        return dict(list(base_config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb64456",
   "metadata": {},
   "source": [
    "### Constants class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07012d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    '''\n",
    "    Constants class.\n",
    "    '''\n",
    "    OBSERVATIONS = 0\n",
    "    CORRECT_GOAL = 1\n",
    "    POSSIBLE_GOALS = 2 \n",
    "\n",
    "    SATELLITE = 0\n",
    "    LOGISTICS = 1\n",
    "    ZENOTRAVEL = 2\n",
    "    BLOCKSWORLD = 3\n",
    "    DRIVERLOG = 4\n",
    "    DEPOTS = 5\n",
    "\n",
    "    MAX_PLAN_LENGTH = 0\n",
    "    MODEL_FILE = 1\n",
    "    DICTIONARIES_DICT = 2\n",
    "\n",
    "    SMALL = 0\n",
    "    COMPLETE = 1\n",
    "    PERCENTAGE = 2\n",
    "\n",
    "    MODELS_DIR = '../models/'\n",
    "    DICTIONARIES_DIR = '../data/dictionaries/'\n",
    "    # MODELS_DIR = './incremental_models/'\n",
    "\n",
    "    MODEL_LOGISTICS = \"blocksworld_small.h5\"\n",
    "    MODEL_SATELLITE = \"satellite_small.h5\"\n",
    "    MODEL_ZENOTRAVEL = \"zenotravel_small.h5\"\n",
    "    MODEL_BLOCKSWORLS = \"blocksworld_small.h5\"\n",
    "    MODEL_DRIVERLOG = \"driverlog_small.h5\"\n",
    "    MODEL_DEPOTS = \"depots_small.h5\"\n",
    "\n",
    "    MAX_PLAN_PERCENTAGE = 0.7\n",
    "\n",
    "    TABLE_HEADERS = ['', 'Pereira', 'Our', 'Support']\n",
    "\n",
    "    CUSTOM_OBJECTS = {'AttentionWeights': AttentionWeights,\n",
    "                   'ContextVector' : ContextVector,\n",
    "                   'custom_multilabel_loss_v3' : BinaryCrossentropy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc128c",
   "metadata": {},
   "source": [
    "### Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2882311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanLengthError(Exception):\n",
    "    pass\n",
    "\n",
    "class FileFormatError(Exception):\n",
    "    pass\n",
    "\n",
    "class UnknownIndexError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871bfbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Custom Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698999d5",
   "metadata": {},
   "source": [
    "### Unpack files methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6ed7d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unzip_file(file_path: str, target_dir: str) -> None:\n",
    "    '''\n",
    "    Unzip a file in an empty directory. The directory is \n",
    "    emptied before the execution.\n",
    "    \n",
    "    Args:\n",
    "        file_path:\n",
    "            A string that contains the path\n",
    "            to the .zip file.\n",
    "        \n",
    "        target_dir:\n",
    "            A string that contains the path \n",
    "            to the target directory. This \n",
    "            directory is created if it doesn't\n",
    "            exist and it is emptied if it exists.\n",
    "        \n",
    "    '''\n",
    "    if os.path.exists(target_dir):\n",
    "        for f in os.listdir(target_dir):\n",
    "            os.remove(join(target_dir, f))\n",
    "        os.rmdir(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    os.system(f'unzip -qq {file_path} -d {target_dir}')\n",
    "    \n",
    "def unpack_bz2(file_path: str, target_dir: str) -> None:\n",
    "    '''\n",
    "    Unpack a .bz2 file in an empty directory. The directory \n",
    "    is emptied before the execution.\n",
    "    \n",
    "    Args:\n",
    "        file_path:\n",
    "            A string that contains the path\n",
    "            to the .bz2 file.\n",
    "        \n",
    "        target_dir:\n",
    "            A string that contains the path \n",
    "            to the target directory. This \n",
    "            directory is created if it doesn't\n",
    "            exist and it is emptied if it exists.\n",
    "        \n",
    "    '''\n",
    "    if os.path.exists(target_dir):\n",
    "        for f in os.listdir(target_dir):\n",
    "            os.remove(join(target_dir, f))\n",
    "        os.rmdir(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    os.system(f'tar -xf {file_path} -C {target_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a2ca8",
   "metadata": {},
   "source": [
    "### Input parse methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17603a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file: str, binary: bool = False, use_pickle: bool = False):\n",
    "    '''\n",
    "    Get file content from path.\n",
    "    \n",
    "    Args:\n",
    "        file:\n",
    "            A string that contains the path\n",
    "            to the file.\n",
    "        binary:\n",
    "            Optional. True if the file is a \n",
    "            binary file.\n",
    "        use_pickle:\n",
    "            Optional. True if the file was \n",
    "            saved using pickle.\n",
    "            \n",
    "    Returns:\n",
    "        The content of the file.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError:\n",
    "            An error accessing the file\n",
    "    '''\n",
    "    operation = 'r'\n",
    "    if binary:\n",
    "        operation += 'b'\n",
    "    with open(file, operation) as rf:\n",
    "        if use_pickle:\n",
    "            output = pickle.load(rf)\n",
    "        else:\n",
    "            output = rf.readlines()\n",
    "        rf.close()\n",
    "    return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7153ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(read_file: str, content_type: int, dictionary: dict = None):\n",
    "    '''\n",
    "    Parse different input files.\n",
    "    \n",
    "    Args:\n",
    "        read_file: \n",
    "            String containing the path to the file.\n",
    "        content_type: \n",
    "            Integer representing the kind of parse to apply.\n",
    "                0: observations file,\n",
    "                1: correct goal file, \n",
    "                2: possible goals file\n",
    "        \n",
    "    Returns:\n",
    "        A list of strings that contains the parsed elements.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError: \n",
    "            An error regarding the action format in \n",
    "            the file   \n",
    "    '''\n",
    "    \n",
    "    msg_empty = f'File {read_file} is empty.'\n",
    "    msg_index = f'Content type {content_type} is unknown.' \n",
    "    \n",
    "    elements = list()\n",
    "    \n",
    "    lines = load_file(read_file)\n",
    "    if len(lines) == 0:\n",
    "        raise FileFormatError(msg_empty)\n",
    "    if content_type == C.OBSERVATIONS:\n",
    "        elements = parse_observations(lines, dictionary)\n",
    "    elif content_type == C.POSSIBLE_GOALS:\n",
    "        elements = parse_possible_goals(lines, dictionary)\n",
    "    elif content_type == C.CORRECT_GOAL:\n",
    "        elements = parse_correct_goal(lines[0], dictionary)\n",
    "    else:\n",
    "        raise UnknownIndexError(msg_index)\n",
    "    \n",
    "    if len(elements) > 0:    \n",
    "        return elements\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "        \n",
    "\n",
    "def remove_parentheses(line: str) -> str:\n",
    "    '''\n",
    "    Remove parentheses from a string.\n",
    "    \n",
    "    Args:\n",
    "        line: a string that is enclosed in parentheses.\n",
    "        For example:\n",
    "        \n",
    "        \"(string example)\"\n",
    "        \n",
    "    Returns:\n",
    "        The string without the parenteses.\n",
    "        None if the string is empty.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError: error handling the string\n",
    "    '''\n",
    "    \n",
    "    msg = (f'Error while parsing a line. Expected \"(custom '\n",
    "    +f'text)\" but found \"{line}\"')\n",
    "    \n",
    "    line = line.strip()\n",
    "    if line.startswith('(') and line.endswith(')'):\n",
    "        element = line[1:-1]\n",
    "        element = element.strip()\n",
    "        if len(element) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return element\n",
    "    elif len(line) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        raise FileFormatError(msg)\n",
    "        \n",
    "def retrieve_from_dict(key: str, dictionary: dict):\n",
    "    '''\n",
    "    Return the dictionary value given the key.\n",
    "    \n",
    "    Args:\n",
    "        key:\n",
    "            A string that is the key.\n",
    "        dictionary:\n",
    "            A dict.\n",
    "            \n",
    "    Returns:\n",
    "        The value corresponding to the key.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error accessing the dictionary.\n",
    "    '''\n",
    "    \n",
    "    msg_error = f'Key {key.upper()} is not in the dictionary'\n",
    "    \n",
    "    try:\n",
    "        return dictionary[key.upper()]\n",
    "    except KeyError:\n",
    "        print(msg_error)\n",
    "        np.random.seed(47)\n",
    "        return np.random.randint(0,len(dictionary))\n",
    "\n",
    "def parse_correct_goal(line: str, goals_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Parse the fluents that compose a goal.\n",
    "    \n",
    "    Args:\n",
    "        line: \n",
    "            A string that contains one or more \n",
    "            fluents in the goal. Fluents are \n",
    "            enclosed in parentheses and separated\n",
    "            by commas. For example:\n",
    "            \n",
    "            \"(fluent1), (fluent2),  (fluent3)\"\n",
    "        \n",
    "        goals_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            fluent to its unique identifier.\n",
    "    \n",
    "    Returns:\n",
    "        A list of strings containing each fluent \n",
    "        without parentheses.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty = 'Parsed goal is empty.'\n",
    "    \n",
    "    goal = list()\n",
    "    line = line.strip()\n",
    "    fluents = line.split(',')\n",
    "    for f in fluents:\n",
    "        fluent = remove_parentheses(f)\n",
    "        if fluent is not None:\n",
    "            if goals_dict is not None:\n",
    "                fluent = retrieve_from_dict(fluent, goals_dict)\n",
    "            goal.append(fluent)\n",
    "    if len(goal) > 0:\n",
    "        return goal\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "    \n",
    "\n",
    "        \n",
    "def parse_observations(lines: list, obs_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Removes parentheses and empty strings from \n",
    "    the observations list.\n",
    "    \n",
    "    Args:\n",
    "        lines: \n",
    "            List of strings that contains the \n",
    "            observations. Each observation is\n",
    "            enclosed in parentheses. For \n",
    "            example:\n",
    "            \n",
    "            ['(observation1)', '', '(observation2)']\n",
    "        \n",
    "        obs_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            observation to its unique identifier.\n",
    "            \n",
    "    Returns:\n",
    "        The input list without parentheses and\n",
    "        empty strings.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty='Observations list is empty.'\n",
    "    \n",
    "    observations = list()\n",
    "    \n",
    "    for line in lines:\n",
    "        observation = remove_parentheses(line)\n",
    "        if observation is not None:\n",
    "            if obs_dict is not None:\n",
    "                observation = retrieve_from_dict(observation, obs_dict)\n",
    "            observations.append(observation)\n",
    "    if len(observations)>0:\n",
    "        return observations\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "\n",
    "def parse_possible_goals(lines: list, goals_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Parse a list of goals.\n",
    "    \n",
    "    Args:\n",
    "        lines:\n",
    "            A list of strings that contains each\n",
    "            possible goal.\n",
    "            \n",
    "        goals_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            fluent to its unique identifier.\n",
    "    \n",
    "    Returns:\n",
    "        A list of lists. Each list contains the fluents\n",
    "        that compose the goal represented as a string.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty='Possible goals list is empty.'\n",
    "    \n",
    "    goals=list()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            goals.append(parse_correct_goal(line, goals_dict))\n",
    "    if len(goals) > 0:\n",
    "        return goals\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a5a07",
   "metadata": {},
   "source": [
    "### Model related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1359ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_domain(domain: Union[str, int]) -> int:\n",
    "    '''\n",
    "    Converts domain name into integer\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            A string or an int that represents\n",
    "            a domain.\n",
    "    \n",
    "    Returns:\n",
    "        An integer associated to a specific domain.\n",
    "        \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error parsing the domain arg.\n",
    "    '''\n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "           f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "           f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "           f'{C.ZENOTRAVEL} : zenotravel, {C.DRIVERLOG}: driverlog,' + \n",
    "           f'{C.DEPOTS}: depots.')\n",
    "           \n",
    "    if (str(domain).isdigit() and int(domain) == C.SATELLITE) or str(domain).lower().strip() == 'satellite':\n",
    "        return C.SATELLITE\n",
    "    elif (str(domain).isdigit() and int(domain) == C.LOGISTICS) or str(domain).lower().strip() == 'logistics':\n",
    "        return C.LOGISTICS\n",
    "    elif (str(domain).isdigit() and int(domain) == C.BLOCKSWORLD) or str(domain).lower().strip() == 'blocksworld':\n",
    "        return C.BLOCKSWORLD\n",
    "    elif (str(domain).isdigit() and int(domain) == C.ZENOTRAVEL) or str(domain).lower().strip() == 'zenotravel':\n",
    "        return C.ZENOTRAVEL\n",
    "    elif (str(domain).isdigit() and int(domain) == C.DRIVERLOG) or str(domain).lower().strip() == 'driverlog':\n",
    "        return C.DRIVERLOG\n",
    "    elif (str(domain).isdigit() and int(domain) == C.DEPOTS) or str(domain).lower().strip() == 'depots':\n",
    "        return C.DEPOTS\n",
    "    else:\n",
    "        raise KeyError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5de0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(domain: int):\n",
    "    '''\n",
    "    Loads the model for a specific domain.\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            an integer associated to a specific \n",
    "            domain.\n",
    "            \n",
    "    Returns:\n",
    "        The Model loaded for the domain or None\n",
    "        if there is no model in memory.\n",
    "        \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error parsing the domain arg.\n",
    "    '''\n",
    "\n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "       f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "       f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "       f'{C.ZENOTRAVEL} : zenotravel, {C.DRIVERLOG}: driverlog,' + \n",
    "       f'{C.DEPOTS}: depots.')\n",
    "    \n",
    "    if domain == C.LOGISTICS:\n",
    "        return C.MODEL_LOGISTICS\n",
    "    elif domain == C.SATELLITE:\n",
    "        return C.MODEL_SATELLITE\n",
    "    elif domain == C.DEPOTS:\n",
    "        return C.MODEL_DEPOTS\n",
    "    elif domain == C.BLOCKSWORLD:\n",
    "        return C.MODEL_BLOCKSWORLS\n",
    "    elif domain == C.DRIVERLOG:\n",
    "        return C.MODEL_DRIVERLOG\n",
    "    elif domain == C.ZENOTRAVEL:\n",
    "        return C.MODEL_ZENOTRAVEL\n",
    "    else:\n",
    "        raise KeyError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6e6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_related(domain: int, element: int, model_type: int = C.SMALL, \n",
    "                       percentage: float = 0) -> Union[int, str]:\n",
    "    '''\n",
    "    Returns domain related information\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            an integer associated to a specific \n",
    "            domain.\n",
    "        \n",
    "        element:\n",
    "            an integer associated to a specific\n",
    "            piece of information to retrieve.\n",
    "        \n",
    "        model_type:\n",
    "            an integer associated to the type\n",
    "            of RNN model in use.\n",
    "        \n",
    "        percentage:\n",
    "            a float that represents the model\n",
    "            percentage to use. Use only with\n",
    "            model_type = C.PERCENTAGE.\n",
    "    \n",
    "    Returns: \n",
    "        Max plan size if element=C.MAX_PLAN_LENGTH,\n",
    "        Model file if element=C.MODEL_FILE\n",
    "        Dictionaries directory if element=C.DICTIONARIES_DICT\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "           f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "           f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "           f'{C.ZENOTRAVEL} : zenotravel.')\n",
    "    if domain == C.LOGISTICS:\n",
    "        v = {\n",
    "            'max_plan_len' : 50,\n",
    "            'name' : 'logistics',\n",
    "        }\n",
    "    elif domain == C.SATELLITE:\n",
    "        v = {\n",
    "            'max_plan_len' : 40,\n",
    "            'name' : 'satellite',\n",
    "        }\n",
    "    elif domain == C.ZENOTRAVEL:\n",
    "        v = {\n",
    "            'max_plan_len' : 40,\n",
    "            'name' : 'zenotravel',\n",
    "        }\n",
    "    elif domain == C.BLOCKSWORLD:\n",
    "        v = {\n",
    "            'max_plan_len' : 75,\n",
    "            'name' : 'blocksworld',\n",
    "        }\n",
    "    elif domain == C.DRIVERLOG:\n",
    "        v = {\n",
    "            'max_plan_len' : 70,\n",
    "            'name' : 'driverlog',\n",
    "        }\n",
    "    elif domain == C.DEPOTS:\n",
    "        v = {\n",
    "            'max_plan_len' : 64,\n",
    "            'name' : 'depots'\n",
    "        }\n",
    "    else:\n",
    "        raise KeyError(msg)\n",
    "        \n",
    "    if element == C.MAX_PLAN_LENGTH:\n",
    "        return int(v['max_plan_len']*C.MAX_PLAN_PERCENTAGE)\n",
    "    \n",
    "    elif element == C.MODEL_FILE:\n",
    "        if model_type == C.COMPLETE:\n",
    "            return f'{v[\"name\"]}.h5'\n",
    "        elif model_type == C.SMALL:\n",
    "            return f'{v[\"name\"]}_small.h5'\n",
    "        elif model_type == C.PERCENTAGE:\n",
    "            return f'{v[\"name\"]}_{int(percentage*100)}perc.h5'\n",
    "        \n",
    "    elif element == C.DICTIONARIES_DICT:\n",
    "        return join(C.DICTIONARIES_DIR, f'{v[\"name\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e6def",
   "metadata": {},
   "source": [
    "### Domain component methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e191963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observations_array(observations: list, max_plan_length: int) -> np.ndarray:\n",
    "    '''\n",
    "    Create an array of observations index.\n",
    "    \n",
    "    Args:\n",
    "        observations: \n",
    "            A list of action names\n",
    "            \n",
    "        max_plan_length:\n",
    "            An integer that contains the maximum size of\n",
    "            the list that will be considered.\n",
    "    \n",
    "    Returns:\n",
    "        An array that contains the observations' indexes\n",
    "    '''\n",
    "\n",
    "    WARNING_MSG = (f'The action trace is too long. Only the last {max_plan_length}'+\n",
    "                 f'actions will be considered.')\n",
    "\n",
    "    observations_array = np.zeros((1, max_plan_length))\n",
    "    if len(observations) > max_plan_length:\n",
    "        print(WARNING_MSG)\n",
    "        observations = observations[::-1]\n",
    "    for index, observation in enumerate(observations):\n",
    "        if index < max_plan_length:\n",
    "            observations_array[0][index] = int(observation)\n",
    "    return observations_array\n",
    "\n",
    "\n",
    "def get_predictions(observations: list, \n",
    "                    max_plan_length: int, \n",
    "                    domain: int) -> np.ndarray:\n",
    "    '''\n",
    "    Return the model predictions.\n",
    "    \n",
    "    Args:\n",
    "        observations:\n",
    "            A list of action names.\n",
    "        \n",
    "        max_plan_length:\n",
    "            An integer that contains the maximum size of\n",
    "            the list that will be considered.\n",
    "        \n",
    "        domain:\n",
    "            An integer associated to a specific domain.\n",
    "    \n",
    "    Returns:\n",
    "        The model predictions.\n",
    "    '''\n",
    "\n",
    "    model = get_model(domain)\n",
    "    \n",
    "    model_input = tf.convert_to_tensor(get_observations_array(observations, max_plan_length))\n",
    "    y_pred = model.predict(model_input)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62884125",
   "metadata": {},
   "source": [
    "### GR Instance component methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14f6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(prediction: np.ndarray, possible_goal: list) -> float:\n",
    "    '''\n",
    "    Returns the score for a possible goal.\n",
    "    \n",
    "    Args:\n",
    "        prediction:\n",
    "            An array that contains the model prediction.\n",
    "        \n",
    "        possible_goal:\n",
    "            A list that contains the possible goal indexes.\n",
    "        \n",
    "    Returns:\n",
    "        An float that represents the score of the possible goal.\n",
    "    '''\n",
    "    \n",
    "    score=0\n",
    "    \n",
    "    for index in possible_goal:\n",
    "        score += prediction[0][int(index)]\n",
    "    return score\n",
    "\n",
    "def get_scores(prediction: np.ndarray, possible_goals: list) -> np.ndarray:\n",
    "    '''\n",
    "    Returns the scores for all possible goals.\n",
    "    \n",
    "    Args:\n",
    "        prediction:\n",
    "            An array that contains the model prediction.\n",
    "        \n",
    "        possible_goals:\n",
    "            A list of possible goals; each possible goal is represented as a\n",
    "            list\n",
    "        \n",
    "    Returns:\n",
    "        An array that contains the score of each of the possible goals.\n",
    "    '''\n",
    "    scores = np.zeros((len(possible_goals, )), dtype=float)\n",
    "    for index, possible_goal in enumerate(possible_goals):\n",
    "        scores[index] = get_score(prediction, possible_goal)\n",
    "    return scores\n",
    "        \n",
    "\n",
    "def get_max(scores: np.ndarray) -> list:\n",
    "    '''\n",
    "    Returns a list with the index (or indexes) of the highest scores.\n",
    "    \n",
    "    Args:\n",
    "        scores:\n",
    "            An array that contains the scores as floats.\n",
    "    \n",
    "    Returns:\n",
    "        A list thet contains the indexes of the highest score.\n",
    "    '''\n",
    "    max_element = -1\n",
    "    index_max = list()\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > max_element:\n",
    "            max_element = scores[i]\n",
    "            index_max = [i]\n",
    "        elif scores[i] == max_element:\n",
    "            index_max.append(i)\n",
    "\n",
    "    return index_max\n",
    "    \n",
    "def get_result(scores: np.ndarray, correct_goal: int) -> bool:\n",
    "    '''\n",
    "    Computes if the goal recognition task is successfull.\n",
    "    \n",
    "    Args:\n",
    "        scores:\n",
    "            An array of floats that contains a score for \n",
    "            each possible goal\n",
    "        correct_goal: \n",
    "            An integer that represents the index of the \n",
    "            correct goal\n",
    "            \n",
    "    Returns:\n",
    "        True if the maximum score index corresponds to the \n",
    "        correct goal index, False otherwise.\n",
    "    '''\n",
    "    idx_max_list = get_max(scores)\n",
    "    if len(idx_max_list) == 1:\n",
    "        idx_max = idx_max_list[0]\n",
    "    else:\n",
    "        print(f'Algorithm chose randomly one of {len(idx_max_list)} equals candidates.')\n",
    "        idx_max = idx_max_list[np.random.randint(0, len(idx_max_list))]\n",
    "    if idx_max == correct_goal:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_correct_goal_idx(correct_goal: list, possible_goals: list) -> int:\n",
    "    '''\n",
    "    Conputes the correct goal index.\n",
    "    \n",
    "    Args:\n",
    "        correct_goal:\n",
    "            A list of strings that contains the correct goal\n",
    "            fluents.\n",
    "        possible_goals:\n",
    "            A list of possible goals; each possible goal is represented as a\n",
    "            list.\n",
    "    \n",
    "    Returns:\n",
    "        The index of the correct goal in the possible goals list.\n",
    "        None if the possible goal list does not contain the correct goal.\n",
    "    '''\n",
    "    \n",
    "    for index, possible_goal in enumerate(possible_goals):\n",
    "        possible_goal = np.sort(possible_goal)\n",
    "        correct_goal = np.sort(correct_goal)\n",
    "        if np.all(possible_goal == correct_goal):\n",
    "            return index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16711946",
   "metadata": {},
   "source": [
    "### GRNet execution methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea3f97",
   "metadata": {},
   "source": [
    "### Noisy mask methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_mask_file(mask_file_path: str) -> dict:\n",
    "    '''\n",
    "    Load a mask file containing noisy observations.\n",
    "    \n",
    "    Args:\n",
    "        mask_file_path:\n",
    "            Path to the JSON mask file.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing the mask data.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError:\n",
    "            If the mask file doesn't exist.\n",
    "    '''\n",
    "    with open(mask_file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def apply_mask(observations: list, problem_file: str, mask_data: dict) -> list:\n",
    "    '''\n",
    "    Apply a noisy mask to observations if available.\n",
    "    \n",
    "    Args:\n",
    "        observations:\n",
    "            Original list of observations.\n",
    "        problem_file:\n",
    "            Name of the problem file (e.g., 'blocksworld_p003292_hyp=hyp-19_10.zip').\n",
    "        mask_data:\n",
    "            Dictionary containing mask information loaded from the mask file.\n",
    "    \n",
    "    Returns:\n",
    "        Modified observations list if mask is found, otherwise original observations.\n",
    "    '''\n",
    "    if problem_file in mask_data:\n",
    "        problem_mask = mask_data[problem_file]\n",
    "        # Return the noisy observations from the mask\n",
    "        return problem_mask['obs']\n",
    "    else:\n",
    "        # If no mask found for this problem, return original observations\n",
    "        print(f\"Warning: No mask found for {problem_file}, using original observations.\")\n",
    "        return observations\n",
    "\n",
    "def get_mask_path(domain: int, percentage_dir: str, noise_level: int) -> str:\n",
    "    '''\n",
    "    Get the path to the mask file for a given domain, percentage, and noise level.\n",
    "    \n",
    "    Args:\n",
    "        domain:\n",
    "            Integer representing the domain.\n",
    "        percentage_dir:\n",
    "            String representing the percentage directory (e.g., '10', '30', '50').\n",
    "        noise_level:\n",
    "            Integer representing the noise percentage (10, 20, or 30).\n",
    "    \n",
    "    Returns:\n",
    "        Path to the mask file.\n",
    "    '''\n",
    "    domain_name = get_domain_related(domain, C.MODEL_FILE).split('_')[0]\n",
    "    mask_base_dir = '../data/validator_testset/noisy_masks'\n",
    "    mask_file = f'{noise_level}_mask.json'\n",
    "    return join(mask_base_dir, domain_name, percentage_dir, mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f87cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_models(model_type: int, percentage: float)-> None:\n",
    "    '''\n",
    "    Loads in memory all the models.\n",
    "    \n",
    "    Args:\n",
    "        model_type:\n",
    "            an integer associated to the type\n",
    "            of RNN model in use.\n",
    "        \n",
    "        percentage:\n",
    "            a float that represents the model\n",
    "            percentage to use. Use only with\n",
    "            model_type = C.PERCENTAGE.\n",
    "    \n",
    "    Returns:\n",
    "        None   \n",
    "    '''\n",
    "    \n",
    "    model_file = get_domain_related(C.LOGISTICS, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_LOGISTICS =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.SATELLITE, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_SATELLITE = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.ZENOTRAVEL, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_ZENOTRAVEL = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.DEPOTS, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_DEPOTS = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.DRIVERLOG, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_DRIVERLOG =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.BLOCKSWORLD, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_BLOCKSWORLS =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06eb9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(obs_file: str, \n",
    "            goals_dict_file: Union[str, None],\n",
    "            actions_dict_file: Union[str, None],\n",
    "            possible_goals_file: str, \n",
    "            correct_goal_file: str, \n",
    "            domain: Union[str, int], \n",
    "            verbose: int = 0,\n",
    "            mask_data: Union[dict, None] = None,\n",
    "            problem_file: Union[str, None] = None) -> list:\n",
    "    '''\n",
    "    Run the goal recognition experiment\n",
    "\n",
    "    Args:\n",
    "        obs_file:\n",
    "            Path of the file that contains the\n",
    "            observations (plan)\n",
    "\n",
    "        goals_dict_file:\n",
    "            Path of the file that contains the\n",
    "            goals dictionaries. If None it is\n",
    "            retrieved from its default location.\n",
    "\n",
    "        actions_dict_file:\n",
    "            Path of the file that contains the\n",
    "            actions dictionaries. If None it is\n",
    "            retrieved from its default location.\n",
    "\n",
    "        possible_goals_file:\n",
    "            Path of the file that contains the\n",
    "            possible goals.\n",
    "\n",
    "        correct_goal_file:\n",
    "            Path of the file that contains the\n",
    "            correct goal.\n",
    "\n",
    "        domain:\n",
    "            String that contains the name of the\n",
    "            domain or integer that corresponds to\n",
    "            a domain.\n",
    "\n",
    "        verbose:\n",
    "            Integer that corresponds to how much\n",
    "            information is printed. 0 = no info,\n",
    "            2 = max info\n",
    "        \n",
    "        mask_data:\n",
    "            Optional. Dictionary containing noisy mask data.\n",
    "            If provided, observations will be replaced with noisy ones.\n",
    "        \n",
    "        problem_file:\n",
    "            Optional. Name of the problem file (e.g., 'problem_10.zip').\n",
    "            Required when mask_data is provided.\n",
    "\n",
    "    Returns:\n",
    "         A list that contains the result, the correct\n",
    "         goal index and the predicted goal index.\n",
    "    '''\n",
    "\n",
    "    domain = parse_domain(domain)\n",
    "    if goals_dict_file is None:\n",
    "        goals_dict_file = join(get_domain_related(domain, C.DICTIONARIES_DICT), 'dizionario_goal')\n",
    "    goals_dict = load_file(goals_dict_file, binary=True, use_pickle=True)\n",
    "    if actions_dict_file is None:\n",
    "        actions_dict_file = join(get_domain_related(domain, C.DICTIONARIES_DICT), 'dizionario')\n",
    "    actions_dict = load_file(actions_dict_file, binary=True, use_pickle=True)\n",
    "    observations = parse_file(obs_file, C.OBSERVATIONS, actions_dict)\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask_data is not None and problem_file is not None:\n",
    "        observations = apply_mask(observations, problem_file, mask_data)\n",
    "        if verbose > 1:\n",
    "            print(f'Applied noisy mask for {problem_file}')\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print('Observed actions:\\n')\n",
    "        for o in observations:\n",
    "            print(o)\n",
    "    possible_goals = parse_file(possible_goals_file, C.POSSIBLE_GOALS, goals_dict)\n",
    "    \n",
    "    max_plan_length = get_domain_related(domain, C.MAX_PLAN_LENGTH)\n",
    "    predictions = get_predictions(observations, max_plan_length, domain)\n",
    "    scores = get_scores(predictions, possible_goals)\n",
    "    if verbose > 0:\n",
    "        for index, goal in enumerate(possible_goals):\n",
    "            print(f'{index} - {goal} : {scores[index]}')\n",
    "    \n",
    "    correct_goal = parse_file(correct_goal_file, C.CORRECT_GOAL, goals_dict) \n",
    "    correct_goal_idx = get_correct_goal_idx(correct_goal, possible_goals)\n",
    "    result = get_result(scores, correct_goal_idx)\n",
    "    if verbose > 0:\n",
    "        print(f'Predicted goal is {get_max(scores)[0]}')\n",
    "        print(f'Correct goal is {correct_goal_idx} - {correct_goal}')\n",
    "    return [result, correct_goal_idx, get_max(scores)[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de47d2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GRNet execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4311f",
   "metadata": {},
   "source": [
    "Do not change these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34174acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type=C.SMALL \n",
    "percentage=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6461bf",
   "metadata": {},
   "source": [
    "Change these values to fit your execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e2414",
   "metadata": {},
   "source": [
    "### Noisy Test Configuration\n",
    "\n",
    "To run experiments with noisy observations, set `use_noisy_masks = True` and choose a noise level (10, 20, or 30).\n",
    "\n",
    "**How it works:**\n",
    "- When `use_noisy_masks = True`, the system loads the corresponding mask file from `data/validator_testset/noisy_masks/`\n",
    "- The mask file contains modified observations where X% of actions have been replaced with random valid ones\n",
    "- The modified observations are used instead of the original ones for testing\n",
    "\n",
    "**Example configurations:**\n",
    "- `use_noisy_masks = False` → Standard test (original observations)\n",
    "- `use_noisy_masks = True, noise_level = 10` → Test with 10% noisy observations\n",
    "- `use_noisy_masks = True, noise_level = 20` → Test with 20% noisy observations\n",
    "- `use_noisy_masks = True, noise_level = 30` → Test with 30% noisy observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3115b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = C.BLOCKSWORLD\n",
    "domain_dir = f\"../data/blocksworld\"\n",
    "source_dir = f\"./tmp\"\n",
    "verbose = 0\n",
    "\n",
    "# Noisy test configuration\n",
    "use_noisy_masks = False # Set to True to use noisy masks\n",
    "noise_level = 10  # Options: 10, 20, or 30 (percentage of noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9d2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_models(model_type=model_type, percentage=percentage)\n",
    "\n",
    "# perc_list = [0.1, 0.3, 0.5, 0.7, 1] \n",
    "perc_list = [0.1, 1]\n",
    "results = list()\n",
    "times = list()\n",
    "for perc in perc_list:\n",
    "    plans_dir = f'{join(domain_dir, str(int(perc*100)))}'\n",
    "    files = os.listdir(plans_dir)\n",
    "    total=0\n",
    "    correct=0\n",
    "    results_file = [list(), list()]\n",
    "    \n",
    "    # Load mask data if using noisy masks\n",
    "    mask_data = None\n",
    "    if use_noisy_masks:\n",
    "        try:\n",
    "            mask_file_path = get_mask_path(domain, str(int(perc*100)), noise_level)\n",
    "            mask_data = load_mask_file(mask_file_path)\n",
    "            print(f'Loaded mask file: {mask_file_path}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'Warning: Mask file not found at {mask_file_path}. Running without masks.')\n",
    "            mask_data = None\n",
    "    \n",
    "    for j, f in enumerate(files):     \n",
    "        print(f)\n",
    "        if f.endswith('.zip'):\n",
    "            unzip_file(join(plans_dir,f), source_dir)\n",
    "        elif f.endswith('.bz2'):\n",
    "            unpack_bz2(join(plans_dir,f), source_dir)\n",
    "        start_time = time.time()\n",
    "        result = run_experiment(obs_file=join(source_dir, 'obs.dat'),\n",
    "                                goals_dict_file=None,\n",
    "                                actions_dict_file=None,\n",
    "                                possible_goals_file=join(source_dir, 'hyps.dat'),\n",
    "                                correct_goal_file=join(source_dir, 'real_hyp.dat'),\n",
    "                                domain=domain, \n",
    "                                verbose=1,\n",
    "                                mask_data=mask_data,\n",
    "                                problem_file=f)\n",
    "        exec_time = time.time()-start_time\n",
    "        if result[0]:\n",
    "            correct+=1\n",
    "        total +=1\n",
    "        times.append(exec_time)\n",
    "        print(exec_time)\n",
    "        results_file[0].append(result[1])\n",
    "        results_file[1].append(result[2])\n",
    "    results.append(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdd803",
   "metadata": {},
   "source": [
    "### Example: Compare clean vs noisy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70441581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing with 0% noise\n",
      "============================================================\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Accuracy at 10% observations: 0.00%\n",
      "Accuracy at 10% observations: 0.00%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42117/1374631018.py:112: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.all(possible_goal == correct_goal):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Accuracy at 30% observations: 20.00%\n",
      "\n",
      "Overall accuracy with 0% noise: 10.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 10% noise\n",
      "============================================================\n",
      "\n",
      "Accuracy at 30% observations: 20.00%\n",
      "\n",
      "Overall accuracy with 0% noise: 10.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 10% noise\n",
      "============================================================\n",
      "\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/10_mask.json\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/10_mask.json\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Accuracy at 10% observations: 20.00%\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Accuracy at 10% observations: 20.00%\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/10_mask.json\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/10_mask.json\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Accuracy at 30% observations: 0.00%\n",
      "\n",
      "Overall accuracy with 10% noise: 10.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 20% noise\n",
      "============================================================\n",
      "\n",
      "Accuracy at 30% observations: 0.00%\n",
      "\n",
      "Overall accuracy with 10% noise: 10.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 20% noise\n",
      "============================================================\n",
      "\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/20_mask.json\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/20_mask.json\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Accuracy at 10% observations: 20.00%\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Accuracy at 10% observations: 20.00%\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/20_mask.json\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/20_mask.json\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Accuracy at 30% observations: 20.00%\n",
      "\n",
      "Overall accuracy with 20% noise: 20.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 30% noise\n",
      "============================================================\n",
      "\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/30_mask.json\n",
      "Accuracy at 30% observations: 20.00%\n",
      "\n",
      "Overall accuracy with 20% noise: 20.00%\n",
      "\n",
      "============================================================\n",
      "Testing with 30% noise\n",
      "============================================================\n",
      "\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/10/30_mask.json\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Accuracy at 10% observations: 0.00%\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/30_mask.json\n",
      "Accuracy at 10% observations: 0.00%\n",
      "Loaded mask file: ../data/validator_testset/noisy_masks/blocksworld/30/30_mask.json\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Accuracy at 30% observations: 0.00%\n",
      "\n",
      "Overall accuracy with 30% noise: 0.00%\n",
      "\n",
      "============================================================\n",
      "COMPARISON SUMMARY\n",
      "============================================================\n",
      "0% noise - 10% obs: 0.00%\n",
      "0% noise - 30% obs: 20.00%\n",
      "10% noise - 10% obs: 20.00%\n",
      "10% noise - 30% obs: 0.00%\n",
      "20% noise - 10% obs: 20.00%\n",
      "20% noise - 30% obs: 20.00%\n",
      "30% noise - 10% obs: 0.00%\n",
      "30% noise - 30% obs: 0.00%\n",
      "\n",
      "✓ Detailed results saved to: results_blocksworld_detailed_20251105_090639.csv\n",
      "✓ Summary results saved to: results_blocksworld_summary_20251105_090639.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY DATAFRAME\n",
      "============================================================\n",
      " noise_level  total_problems  correct_predictions  accuracy  avg_execution_time\n",
      "           0              10                    1      10.0            0.056704\n",
      "          10              10                    1      10.0            0.059287\n",
      "          20              10                    2      20.0            0.060393\n",
      "          30              10                    0       0.0            0.063961\n",
      "Accuracy at 30% observations: 0.00%\n",
      "\n",
      "Overall accuracy with 30% noise: 0.00%\n",
      "\n",
      "============================================================\n",
      "COMPARISON SUMMARY\n",
      "============================================================\n",
      "0% noise - 10% obs: 0.00%\n",
      "0% noise - 30% obs: 20.00%\n",
      "10% noise - 10% obs: 20.00%\n",
      "10% noise - 30% obs: 0.00%\n",
      "20% noise - 10% obs: 20.00%\n",
      "20% noise - 30% obs: 20.00%\n",
      "30% noise - 10% obs: 0.00%\n",
      "30% noise - 30% obs: 0.00%\n",
      "\n",
      "✓ Detailed results saved to: results_blocksworld_detailed_20251105_090639.csv\n",
      "✓ Summary results saved to: results_blocksworld_summary_20251105_090639.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY DATAFRAME\n",
      "============================================================\n",
      " noise_level  total_problems  correct_predictions  accuracy  avg_execution_time\n",
      "           0              10                    1      10.0            0.056704\n",
      "          10              10                    1      10.0            0.059287\n",
      "          20              10                    2      20.0            0.060393\n",
      "          30              10                    0       0.0            0.063961\n"
     ]
    }
   ],
   "source": [
    "# Example: Run experiments with different noise levels and compare\n",
    "# Run this cell to compare results across all files\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "noise_levels_to_test = [0, 10, 20, 30]  # 0 means no noise (clean test)\n",
    "comparison_results = {}\n",
    "detailed_results = []  # Store detailed results for DataFrame\n",
    "\n",
    "for noise in noise_levels_to_test:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Testing with {noise}% noise')\n",
    "    print(f'{\"=\"*60}\\n')\n",
    "    \n",
    "    use_noisy_masks = (noise > 0)\n",
    "    noise_level = noise if noise > 0 else 10  # Default to 10 if not using masks\n",
    "    \n",
    "    results = list()\n",
    "    times = list()\n",
    "    \n",
    "    for perc in [0.1, 0.3, 0.5, 0.7, 1.0]:\n",
    "        plans_dir = f'{join(domain_dir, str(int(perc*100)))}'\n",
    "        files = os.listdir(plans_dir)  # Process ALL files\n",
    "        \n",
    "        print(f'\\nProcessing {len(files)} files at {int(perc*100)}% observations...')\n",
    "        \n",
    "        # Load mask data if using noisy masks\n",
    "        mask_data = None\n",
    "        if use_noisy_masks:\n",
    "            try:\n",
    "                mask_file_path = get_mask_path(domain, str(int(perc*100)), noise_level)\n",
    "                mask_data = load_mask_file(mask_file_path)\n",
    "                print(f'Loaded mask file: {mask_file_path}')\n",
    "            except FileNotFoundError:\n",
    "                print(f'Warning: Mask file not found. Running without masks.')\n",
    "                mask_data = None\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for idx, f in enumerate(files):\n",
    "            if (idx + 1) % 100 == 0:  # Progress indicator every 100 files\n",
    "                print(f'  Processed {idx + 1}/{len(files)} files...')\n",
    "                \n",
    "            if f.endswith('.zip'):\n",
    "                unzip_file(join(plans_dir,f), source_dir)\n",
    "            elif f.endswith('.bz2'):\n",
    "                unpack_bz2(join(plans_dir,f), source_dir)\n",
    "            else:\n",
    "                continue  # Skip non-archive files\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = run_experiment(obs_file=join(source_dir, 'obs.dat'),\n",
    "                                    goals_dict_file=None,\n",
    "                                    actions_dict_file=None,\n",
    "                                    possible_goals_file=join(source_dir, 'hyps.dat'),\n",
    "                                    correct_goal_file=join(source_dir, 'real_hyp.dat'),\n",
    "                                    domain=domain, \n",
    "                                    verbose=0,\n",
    "                                    mask_data=mask_data,\n",
    "                                    problem_file=f)\n",
    "            exec_time = time.time() - start_time\n",
    "            \n",
    "            # Store detailed results\n",
    "            detailed_results.append({\n",
    "                'noise_level': noise,\n",
    "                'observation_percentage': int(perc*100),\n",
    "                'problem_file': f,\n",
    "                'correct_prediction': result[0],\n",
    "                'correct_goal_idx': result[1],\n",
    "                'predicted_goal_idx': result[2],\n",
    "                'execution_time': exec_time\n",
    "            })\n",
    "            \n",
    "            if result[0]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "        comparison_results[f'{noise}% noise - {int(perc*100)}% obs'] = accuracy\n",
    "        print(f'  ✓ Accuracy at {int(perc*100)}% observations: {accuracy:.2f}% ({correct}/{total})')\n",
    "    \n",
    "    overall_accuracy = (sum([r['correct_prediction'] for r in detailed_results if r['noise_level'] == noise]) / \n",
    "                       len([r for r in detailed_results if r['noise_level'] == noise])) * 100\n",
    "    print(f'\\n  Overall accuracy with {noise}% noise: {overall_accuracy:.2f}%')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('COMPARISON SUMMARY')\n",
    "print('='*60)\n",
    "for noise_label, acc in comparison_results.items():\n",
    "    print(f'{noise_label}: {acc:.2f}%')\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df_detailed = pd.DataFrame(detailed_results)\n",
    "\n",
    "# Create summary DataFrame by noise level\n",
    "summary_data = []\n",
    "for noise in noise_levels_to_test:\n",
    "    noise_results = [r for r in detailed_results if r['noise_level'] == noise]\n",
    "    summary_data.append({\n",
    "        'noise_level': noise,\n",
    "        'total_problems': len(noise_results),\n",
    "        'correct_predictions': sum([r['correct_prediction'] for r in noise_results]),\n",
    "        'accuracy': (sum([r['correct_prediction'] for r in noise_results]) / len(noise_results)) * 100,\n",
    "        'avg_execution_time': np.mean([r['execution_time'] for r in noise_results])\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Create detailed summary by noise level AND observation percentage\n",
    "summary_by_perc_data = []\n",
    "for noise in noise_levels_to_test:\n",
    "    for perc in [10, 30, 50, 70, 100]:\n",
    "        perc_results = [r for r in detailed_results if r['noise_level'] == noise and r['observation_percentage'] == perc]\n",
    "        if perc_results:\n",
    "            summary_by_perc_data.append({\n",
    "                'noise_level': noise,\n",
    "                'observation_percentage': perc,\n",
    "                'total_problems': len(perc_results),\n",
    "                'correct_predictions': sum([r['correct_prediction'] for r in perc_results]),\n",
    "                'accuracy': (sum([r['correct_prediction'] for r in perc_results]) / len(perc_results)) * 100,\n",
    "                'avg_execution_time': np.mean([r['execution_time'] for r in perc_results])\n",
    "            })\n",
    "\n",
    "df_summary_by_perc = pd.DataFrame(summary_by_perc_data)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "domain_name = get_domain_related(domain, C.MODEL_FILE).split('_')[0]\n",
    "\n",
    "# Save to CSV\n",
    "detailed_filename = f'results_{domain_name}_detailed_{timestamp}.csv'\n",
    "summary_filename = f'results_{domain_name}_summary_{timestamp}.csv'\n",
    "summary_by_perc_filename = f'results_{domain_name}_summary_by_perc_{timestamp}.csv'\n",
    "\n",
    "df_detailed.to_csv(detailed_filename, index=False)\n",
    "df_summary.to_csv(summary_filename, index=False)\n",
    "df_summary_by_perc.to_csv(summary_by_perc_filename, index=False)\n",
    "\n",
    "print(f'\\n✓ Detailed results saved to: {detailed_filename}')\n",
    "print(f'✓ Summary results (by noise level) saved to: {summary_filename}')\n",
    "print(f'✓ Summary results (by noise & obs %) saved to: {summary_by_perc_filename}')\n",
    "\n",
    "# Display the summary DataFrames\n",
    "print('\\n' + '='*60)\n",
    "print('SUMMARY BY NOISE LEVEL')\n",
    "print('='*60)\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('SUMMARY BY NOISE LEVEL AND OBSERVATION PERCENTAGE')\n",
    "print('='*60)\n",
    "print(df_summary_by_perc.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c67c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
